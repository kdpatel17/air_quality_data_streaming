# Air Quality Data Streaming Pipeline

This repository provides a Kafka-based data streaming pipeline for real-time air quality telemetry processing. The project leverages Docker and Apache Kafka to simulate a production-grade event-driven architecture, where ingestion is containerized, and consumption runs locally for analytical flexibility.

---

## ğŸ“ Project Structure
air_quality_data_streaming/
â”‚
â”œâ”€â”€ config.json # Configuration file for Kafka and processing parameters
â”œâ”€â”€ data-ingestion.py # Kafka producer (runs inside Docker)
â”œâ”€â”€ data_consume.py # Kafka consumer (run locally)
â”œâ”€â”€ docker-compose.yml # Docker setup for Kafka and producer
â”œâ”€â”€ Dockerfile # Image definition for the producer service
â”œâ”€â”€ thresholds.json # Threshold rules for filtering
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ logger_utils.py # Logging utility
â”œâ”€â”€ .env # Environment variables for Kafka service
â”œâ”€â”€ logs/ # Logs from the pipeline (volume mounted)
â”œâ”€â”€ output/ # Output files from the consumer (volume mounted)
